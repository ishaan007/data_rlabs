{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import csv\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def importData(filename):\n",
    "    X=[]\n",
    "    Y=[]\n",
    "    with open(filename,'r') as data_file:\n",
    "        counter=0\n",
    "        for line in data_file:\n",
    "            if(counter>0):\n",
    "                counter=counter+1\n",
    "                line_list=line.split(\",\")\n",
    "                Y.append(line_list[0])\n",
    "                X.append([line_list[1],line_list[2],line_list[3].split(\"|\")[0].strip(\"\\n\"),line_list[3].split(\"|\")[1].strip(\"\\n\")])\n",
    "                \n",
    "            else:\n",
    "                counter=counter+1\n",
    "        \n",
    "    return X,Y       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y=importData('dataset_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['>10', '<4.4', 'HR', 'AIRTEL'],\n",
       " ['>5', '<5', 'UP', 'JIO'],\n",
       " ['>10', '<5', 'AP', 'AIRTEL'],\n",
       " ['>5', '<5', 'RJ', 'JIO'],\n",
       " ['>10', '<5.6', 'WB', 'VODAFONE'],\n",
       " ['>10', '<5.6', 'HR', 'JIO'],\n",
       " ['>5', '<5', 'TN', 'JIO'],\n",
       " ['>20', '<6', 'DL', 'AIRTEL'],\n",
       " ['>5', '<5', 'MH', 'JIO'],\n",
       " ['>10', '<5.6', 'UK', 'AIRTEL']]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect X1 and X2 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1=[]\n",
    "x2=[]\n",
    "x1=set(x1)\n",
    "x2=set(x2)\n",
    "for i in range(len(X)):\n",
    "    x1.add(float(X[i][0][1:]))\n",
    "    x2.add(float(X[i][1][1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{5.0, 10.0, 20.0, 30.0, 40.0}"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4.0, 4.2, 4.4, 4.6, 4.8, 5.0, 5.2, 5.4, 5.6, 5.8, 6.0}"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Vectorizer for whole data set\n",
      "Dictonary complete\n"
     ]
    }
   ],
   "source": [
    "print('Creating Vectorizer for whole data set')\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "vectorizer_input=[]\n",
    "for eachRow in X:\n",
    "    temp_dic={}\n",
    "    temp_count=1\n",
    "    for data in eachRow:\n",
    "        temp_dic['X'+str(temp_count)] = data\n",
    "        temp_count=temp_count+1\n",
    "    vectorizer_input.append(temp_dic)\n",
    "print(\"Dictonary complete\")\n",
    "output_all = vectorizer.fit(vectorizer_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': '>10', 'X2': '<5.6', 'X3': 'MH', 'X4': 'JIO'}"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_input[3000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3209"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X=vectorizer_input[:2500]\n",
    "train_Y=Y[:2500]\n",
    "test_X=vectorizer_input[2500:]\n",
    "test_Y=Y[2500:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialize the one hot encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('dictvectorizer.pkl', 'wb') as fid:\n",
    "    pickle.dump(vectorizer, fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 55)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(vectorizer_input[0]).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a simple perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 8.37, NNZs: 34, Bias: -3.000000, T: 2500, Avg. loss: 0.817200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 11.66, NNZs: 34, Bias: -3.000000, T: 5000, Avg. loss: 0.806800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 10.68, NNZs: 43, Bias: -2.000000, T: 7500, Avg. loss: 0.796400\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 11.14, NNZs: 46, Bias: -5.000000, T: 10000, Avg. loss: 0.792800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 9.70, NNZs: 41, Bias: -2.000000, T: 12500, Avg. loss: 0.827200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 12.57, NNZs: 42, Bias: -4.000000, T: 15000, Avg. loss: 0.784800\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 10.86, NNZs: 42, Bias: -5.000000, T: 17500, Avg. loss: 0.787200\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 12.41, NNZs: 37, Bias: -3.000000, T: 20000, Avg. loss: 0.780000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 11.49, NNZs: 43, Bias: -3.000000, T: 22500, Avg. loss: 0.816400\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 11.75, NNZs: 42, Bias: -5.000000, T: 25000, Avg. loss: 0.801600\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 12.65, NNZs: 49, Bias: -4.000000, T: 27500, Avg. loss: 0.790400\n",
      "Total training time: 0.00 seconds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:73: DeprecationWarning: n_iter parameter is deprecated in 0.19 and will be removed in 0.21. Use max_iter and tol instead.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=11, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=None, verbose=1, warm_start=False)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Perceptron Model\n",
    "#clf = Perceptron(n_iter=30, verbose=1, eta0=0.2, penalty='l2', alpha=0.001)\n",
    "clf = Perceptron(n_iter=11, verbose=1)\n",
    "clf.fit(vectorizer.transform(train_X),train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=clf.predict(vectorizer.transform(test_X)).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89562764456981669"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_Y,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual Testing to verify predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'X1': '>10', 'X2': '<5.2', 'X3': 'RJ', 'X4': 'VODAFONE'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FALSE'],\n",
       "      dtype='|S5')"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(vectorizer.transform(test_X[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a SVM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(verbose=True)\n",
    "clf.fit(vectorizer.transform(train_X),train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89421720733427368"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions=clf.predict(vectorizer.transform(test_X)).tolist()\n",
    "accuracy_score(test_Y,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87588152327221436"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=55, criterion='entropy')\n",
    "clf.fit(vectorizer.transform(train_X),train_Y)\n",
    "predictions=clf.predict(vectorizer.transform(test_X)).tolist()\n",
    "accuracy_score(test_Y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
